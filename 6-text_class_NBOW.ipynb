{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z6XhdHbvqaaK"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch \n",
        "import torch.autograd as autograd \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add shortcut to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcwWKdQXryVV",
        "outputId": "15f502fb-739e-4361-a84d-c2476e556391"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NBOW model for text classification\n",
        "Neural bag of words (NBOW) model for a text classification task described here:\n",
        "https://people.cs.umass.edu/~miyyer/pubs/2015_acl_dan.pdf "
      ],
      "metadata": {
        "id": "A2XZkoairX5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subjectivity Dataset\n",
        "The subjectivity dataset has 5000 subjective and 5000 objective processed sentences. To get the data:"
      ],
      "metadata": {
        "id": "CsRdrlfpEKyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ-4mtDV0_J8",
        "outputId": "a2e73970-c1fc-443d-b551-5fd17494f64e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir Data_CBOW\n",
        "#!wget http://www.cs.cornell.edu/people/pabo/movie-review-data/rotten_imdb.tar.gz\n",
        "#!tar -xvf rotten_imdb.tar.gz -C Data_CBOW\n"
      ],
      "metadata": {
        "id": "ICtnNq0Eyb64"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Data_CBOW/ "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXXVAVi3rSqC",
        "outputId": "35a31ae3-8166-4dff-d78e-3b9169a1aec0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plot.tok.gt9.5000  quote.tok.gt9.5000  rotten_imdb.tar.gz  subjdata.README.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! head -10 Data_CBOW/plot.tok.gt9.5000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSPJeBeq1jxb",
        "outputId": "37ae1ab2-e1bf-4402-cb5c-052f91300cc1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the movie begins in the past where a young boy named sam attempts to save celebi from a hunter . \n",
            "emerging from the human psyche and showing characteristics of abstract expressionism , minimalism and russian constructivism , graffiti removal has secured its place in the history of modern art while being created by artists who are unconscious of their artistic achievements . \n",
            "spurning her mother's insistence that she get on with her life , mary is thrown out of the house , rejected by joe , and expelled from school as she grows larger with child . \n",
            "amitabh can't believe the board of directors and his mind is filled with revenge and what better revenge than robbing the bank himself , ironic as it may sound . \n",
            "she , among others excentricities , talks to a small rock , gertrude , like if she was alive . \n",
            "this gives the girls a fair chance of pulling the wool over their eyes using their sexiness to poach any last vestige of common sense the dons might have had . \n",
            "styled after vh1's \" behind the music , \" this mockumentary profiles the rise and fall of an internet startup , called icevan . com . \n",
            "being blue is not his only predicament ; he also lacks the ability to outwardly express his emotions . \n",
            "the killer's clues are a perversion of biblical punishments for sins : stoning , burning , decapitation . \n",
            "david is a painter with painter's block who takes a job as a waiter to get some inspiration . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! head -10 Data_CBOW/quote.tok.gt9.5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E1kC2DkDW1d",
        "outputId": "069fddd7-1589-4998-d3e6-087e5ea25f42"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "smart and alert , thirteen conversations about one thing is a small gem . \n",
            "color , musical bounce and warm seas lapping on island shores . and just enough science to send you home thinking . \n",
            "it is not a mass-market entertainment but an uncompromising attempt by one artist to think about another . \n",
            "a light-hearted french film about the spiritual quest of a fashion model seeking peace of mind while in a love affair with a veterinarian who is a non-practicing jew . \n",
            "my wife is an actress has its moments in looking at the comic effects of jealousy . in the end , though , it is only mildly amusing when it could have been so much more . \n",
            "works both as an engaging drama and an incisive look at the difficulties facing native americans . \n",
            "even a hardened voyeur would require the patience of job to get through this interminable , shapeless documentary about the swinging subculture . \n",
            "when perry fists a bull at the moore farm , it's only a matter of time before he gets the upper hand in matters of the heart . \n",
            "the characters . . . are paper-thin , and their personalities undergo radical changes when it suits the script . \n",
            "the script is a tired one , with few moments of joy rising above the stale material . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = Path(\"Data_CBOW\")"
      ],
      "metadata": {
        "id": "MqkotDrn1j0C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(PATH.iterdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4OKWeni1j26",
        "outputId": "e97fdac6-3afd-4091-b961-22122304c6e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('Data_CBOW/subjdata.README.1.0'),\n",
              " PosixPath('Data_CBOW/quote.tok.gt9.5000'),\n",
              " PosixPath('Data_CBOW/plot.tok.gt9.5000'),\n",
              " PosixPath('Data_CBOW/rotten_imdb.tar.gz')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization\n",
        "Tokenization is the task of chopping up text into pieces, called tokens.\n"
      ],
      "metadata": {
        "id": "PCsESSXzEbLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need each line in the file \n",
        "def read_file(path):\n",
        "    \"\"\" Read file returns a list of lines.\n",
        "    \"\"\"\n",
        "    with open(path, encoding = \"ISO-8859-1\") as f:\n",
        "        content = f.readlines()\n",
        "    return content"
      ],
      "metadata": {
        "id": "sSfbtsQ_H-qJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj_lines = read_file(PATH/\"plot.tok.gt9.5000\")\n"
      ],
      "metadata": {
        "id": "LiwUZwXeH-uq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj_lines[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2f176H0EH-yw",
        "outputId": "6e53a0b1-9a6f-4f7d-90d1-d08e4d045aa2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the movie begins in the past where a young boy named sam attempts to save celebi from a hunter . \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(obj_lines[0].strip().lower().split(\" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD4VbOpWOsAW",
        "outputId": "8ebefd73-67ac-48e5-d873-52eb21426bb5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['the', 'movie', 'begins', 'in', 'the', 'past', 'where', 'a',\n",
              "       'young', 'boy', 'named', 'sam', 'attempts', 'to', 'save', 'celebi',\n",
              "       'from', 'a', 'hunter', '.'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split dataset in train and test\n"
      ],
      "metadata": {
        "id": "IT2EMSHfGbFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sub_content = read_file(PATH/\"quote.tok.gt9.5000\")\n",
        "obj_content = read_file(PATH/\"plot.tok.gt9.5000\")\n",
        "sub_content = np.array([line.strip().lower() for line in sub_content])\n",
        "obj_content = np.array([line.strip().lower() for line in obj_content])\n",
        "sub_y = np.zeros(len(sub_content))\n",
        "obj_y = np.ones(len(obj_content))\n",
        "X = np.append(sub_content, obj_content)\n",
        "y = np.append(sub_y, obj_y)"
      ],
      "metadata": {
        "id": "JtGGEn6p1kdx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sub text and label:\", X[0], y[0])\n",
        "print(\"Obj text and label:\",X[5000], y[5000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB9f9gcw1kgq",
        "outputId": "75478421-6d80-49bb-b690-a81c0f6a8610"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub text and label: smart and alert , thirteen conversations about one thing is a small gem . 0.0\n",
            "Obj text and label: the movie begins in the past where a young boy named sam attempts to save celebi from a hunter . 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "ihMfowBUO8AW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:1], y_train[:1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLLHqj6IO8G8",
        "outputId": "aaa5fb1c-df8e-44a1-f73a-70c3d78bd4e4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['will god let her fall or give her a new path ?'], dtype='<U691'),\n",
              " array([1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word to index mapping\n",
        "Compute a vocabulary of words based on the training set and mapping from word to an index.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GT1-sMnyPwje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "def get_vocab(content):\n",
        "    \"\"\"Computes Dict of counts of words.\n",
        "    \n",
        "    Computes the number of times a word is on a document.\n",
        "    \"\"\"\n",
        "    vocab = defaultdict(float)\n",
        "    for line in content:\n",
        "        words = set(line.split())\n",
        "        for word in words:\n",
        "            vocab[word] += 1\n",
        "    return vocab      "
      ],
      "metadata": {
        "id": "IE5vRk5FO8Js"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the vocabulary from the training set\n",
        "word_count = get_vocab(X_train)\n",
        "#print(word_count)\n",
        "#print(word_count.keys())\n",
        "#print(len(word_count.keys()))"
      ],
      "metadata": {
        "id": "-tnUGCF5O8MU"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete words with frequency < 5\n",
        "for word in list(word_count):\n",
        "    if word_count[word] < 5:\n",
        "        del word_count[word]\n",
        "len(word_count.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmoGA5wwO8PV",
        "outputId": "462f8b4a-45e2-45e7-a702-cecd1bc4adec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4065"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Set an index for each word in the vocab\n",
        "vocab2index = {\"\":0, \"UNK\":1} # init with padding and unknown\n",
        "words = [\"\", \"UNK\"]\n",
        "for word in word_count:\n",
        "    vocab2index[word] = len(words)\n",
        "    words.append(word)"
      ],
      "metadata": {
        "id": "YOEzGepmRIsa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vocab2index\n"
      ],
      "metadata": {
        "id": "r5xoFhJPRT3R"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence encoding\n",
        "Here we encode each sentence as a sequence of indices corresponding to each word."
      ],
      "metadata": {
        "id": "NsndgopCRnJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_len = np.array([len(x.split()) for x in X_train])\n",
        "x_valid_len = np.array([len(x.split()) for x in X_valid])"
      ],
      "metadata": {
        "id": "7IKLDRDfRWhS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.percentile(x_train_len, 99) # let set the max sequence len to N=40\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JdQacMXRlxH",
        "outputId": "0b974515-85d7-4492-f96c-7d391ee7ed88"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55.0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3-x6qfZGRlzz",
        "outputId": "4a01aec0-1bd2-4910-e571-bbf07fe7c718"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'will god let her fall or give her a new path ?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# returns the index of the word or the index or \"UNK\" otherwise\n",
        "vocab2index.get(\"?\", vocab2index[\"UNK\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku1TT2jCRl2T",
        "outputId": "aaa921dd-f736-479b-c750-0e45213ffa4e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in X_train[0].split()])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUWTDFmoRl8c",
        "outputId": "0e441254-09a9-4bd9-f942-299caff83d05"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7, 11,  9, 12,  4,  3,  6, 12, 10,  8,  5,  2])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(s, N=40):\n",
        "    enc = np.zeros(N, dtype=np.int32)\n",
        "    enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in s.split()])\n",
        "    l = min(N, len(enc1))\n",
        "    enc[:l] = enc1[:l]\n",
        "    return enc, l"
      ],
      "metadata": {
        "id": "afo_r4XJSINu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode_sentence(X_train[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Wmcs_qoSIQj",
        "outputId": "cfa0d682-11a5-492e-ee50-bf9a3bdf88bd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 7, 11,  9, 12,  4,  3,  6, 12, 10,  8,  5,  2,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0], dtype=int32), 12)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "bTBiCQjVShDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SubjectivityDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.x = X\n",
        "        self.y = y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x[idx]\n",
        "        x, s = encode_sentence(x)\n",
        "        return x, self.y[idx], s\n",
        "    \n",
        "train_ds = SubjectivityDataset(X_train, y_train)\n",
        "valid_ds = SubjectivityDataset(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "2nbgH3_nSITb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=2\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "1yXmES1bSmyO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y, s = next(iter(train_dl))\n"
      ],
      "metadata": {
        "id": "1ZY3ARVmSm1r"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSvIZJBLSm4b",
        "outputId": "06a47945-349c-414a-9dc1-3839ffa21913"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   1, 2347,   17,    1,    1,   36,   73, 3913,    1,    1,   57,   10,\n",
              "          944, 1570,   18,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0],\n",
              "        [   1,   36, 2506,   36,    1,    1,   36,    1,   36,    1, 3790,   36,\n",
              "            1,   25, 1543,  477, 3552,   60, 4009,   80,   17, 3721,   18,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6CS0-cVSm7z",
        "outputId": "54f005c2-e461-4226-e6c3-6e500564bc29"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lenght of each vector\n",
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "habTSn-USvBW",
        "outputId": "33088b42-4e3d-4bc0-99d2-7b10a2178a09"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([15, 23])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding layer\n",
        "Most deep learning models use a dense vectors of real numbers as representation of words (word embeddings), as opposed to a one-hot encoding representations. The module torch.nn.Embedding is used to represent word embeddings. It takes two arguments: the vocabulary size, and the dimensionality of the embeddings. The embeddings are initialized with random vectors."
      ],
      "metadata": {
        "id": "Xspef5IVTnS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An Embedding module containing 10 words with embedding size 4\n",
        "# Embedding weights will be initialized at random.\n",
        "# Note that the padding_idx has embedding vector 0.\n",
        "\n",
        "embed = nn.Embedding(10, 4, padding_idx=0)\n",
        "embed.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UstY2ZL_SvET",
        "outputId": "ed6170b0-102d-4458-f0f1-d6bc945990c2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.5874,  1.4726, -0.1593,  1.5657],\n",
              "        [ 0.0842,  1.7152,  1.0018, -1.1170],\n",
              "        [ 0.1814, -1.6173,  1.2255, -0.4668],\n",
              "        [-0.4929, -2.5295, -1.2409,  0.8116],\n",
              "        [ 0.8431,  0.2836, -2.2855, -2.5100],\n",
              "        [ 0.1989,  0.2340,  1.7802, -0.8061],\n",
              "        [-1.9849,  0.0965,  0.2781,  0.1412],\n",
              "        [-0.2190,  0.0187,  0.0615,  2.0734],\n",
              "        [ 0.0130,  1.8356, -0.8755,  2.6680]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# given a list of ids (a sentence) we can \"look up\" the embedding corresponing to each id\n",
        "# can you see that some vectors are the same?\n",
        "a = torch.LongTensor([[1,4,1,5,1,0]])\n",
        "embed(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6el84-F4SvHW",
        "outputId": "e19387c0-746c-4181-c27c-665f5aa325f0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5874,  1.4726, -0.1593,  1.5657],\n",
              "         [-0.4929, -2.5295, -1.2409,  0.8116],\n",
              "         [-0.5874,  1.4726, -0.1593,  1.5657],\n",
              "         [ 0.8431,  0.2836, -2.2855, -2.5100],\n",
              "         [-0.5874,  1.4726, -0.1593,  1.5657],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can we get a dense representation for the sentence a?\n",
        "embed(a).sum(dim=1)/5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ydtpXOKwBbj",
        "outputId": "832bae3a-96e3-431f-ec91-0af5d31ee90c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2824,  0.4344, -0.8009,  0.5998]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What if we have two sentences where the first sentence has length 3 and the last sentence has length 2?.\n",
        "# In order to use the same embedding layer we use padding at the end of the second sentence.\n",
        "# Our model will take an average of the word embeddings for each sentence.\n",
        "\n",
        "a = torch.LongTensor([[1,4,1], [1,3,0]])\n",
        "s = torch.FloatTensor([3, 2]) # here is the size of the vector\n",
        "print(embed(a))\n",
        "print(\"--------------------------------------------\")\n",
        "print(embed(a).sum(dim=1) / s.view(s.shape[0], 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LQwMReeSvKD",
        "outputId": "8dade3a4-b18f-4faa-b49b-a6db53e46896"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.5874,  1.4726, -0.1593,  1.5657],\n",
            "         [-0.4929, -2.5295, -1.2409,  0.8116],\n",
            "         [-0.5874,  1.4726, -0.1593,  1.5657]],\n",
            "\n",
            "        [[-0.5874,  1.4726, -0.1593,  1.5657],\n",
            "         [ 0.1814, -1.6173,  1.2255, -0.4668],\n",
            "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)\n",
            "--------------------------------------------\n",
            "tensor([[-0.5559,  0.1386, -0.5199,  1.3144],\n",
            "        [-0.2030, -0.0723,  0.5331,  0.5495]], grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continuous Bag of Words Model\n"
      ],
      "metadata": {
        "id": "5bg5zUr8yhy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_size=100):\n",
        "        super(CBOW, self).__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_size, padding_idx=0)\n",
        "        self.linear1 = nn.Linear(emb_size, 30)\n",
        "        self.linear2 = nn.Linear(30, 1)\n",
        "        \n",
        "    def forward(self, x, s):\n",
        "        x = self.word_emb(x)\n",
        "        x = x.sum(dim=1)/ s.view(s.shape[0], 1)\n",
        "        x = self.linear1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "3PjwUo8Cuhjl"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CBOW(vocab_size=5, emb_size=3)\n",
        "model.word_emb.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZxHlWKqu3Dn",
        "outputId": "d56754ca-2dcc-45eb-f480-c6620bf4912d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0000,  0.0000,  0.0000],\n",
              "        [-1.0605, -0.7193, -0.3752],\n",
              "        [-0.6447, -1.7190,  0.0336],\n",
              "        [-0.2961, -0.8309, -0.3394],\n",
              "        [-1.8844, -1.0602, -0.7543]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model(a, s)\n",
        "y_hat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5VrkAbEuhmQ",
        "outputId": "ce832b0a-aaf6-448a-87d5-a5cd3066ca20"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7080],\n",
              "        [0.4535]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the CBOW model\n"
      ],
      "metadata": {
        "id": "LWmN71pR0LiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(valid_ds)     # 2000\n",
        "V = len(words)    # 4067                         \n",
        "model = CBOW(vocab_size=V, emb_size=50)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=500, shuffle=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=2000)\n",
        "\n",
        "loss_func = nn.BCEWithLogitsLoss(reduction='mean')\n"
      ],
      "metadata": {
        "id": "NyMZcTv_uhpQ"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_metrics(model):\n",
        "    model.eval()\n",
        "    for x, y, s in valid_dl:\n",
        "        s = torch.FloatTensor(s.float()).view(s.shape[0], 1)\n",
        "        y = y.unsqueeze(1)\n",
        "        y_hat = model(x.long(), s)\n",
        "        loss = loss_func(y_hat, y)\n",
        "        boundary = (y_hat.max() - abs(y_hat.min()))/2.0\n",
        "        y_pred = y_hat > boundary\n",
        "#        y_pred = y_hat > 0\n",
        "        correct = (y_pred.float() == y).float().sum() # how many prediction match the true label\n",
        "        accuracy = correct/y_pred.shape[0]\n",
        "    return loss.item(), accuracy.item()"
      ],
      "metadata": {
        "id": "qqcxhkfVuhsB"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy of a random model --> 0.5\n",
        "test_metrics(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv8qIpKX1KjV",
        "outputId": "680e7022-6139-4655-bfac-0ab07e233cb4"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6943347522313706, 0.4975000023841858)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epocs(model, epochs=10, lr=0.01, weight_decay=1e-5):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        for x, y, s in train_dl:\n",
        "            y = y.unsqueeze(1)\n",
        "            s = s.type(torch.Tensor).view(s.shape[0], 1)\n",
        "            y_hat = model(x.long(), s)\n",
        "            loss = loss_func(y_hat, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        val_loss, val_acc = test_metrics(model)\n",
        "        print(\"train_loss: %.3f val_loss: %.3f --- val_accuracy: %.3f\" % (loss.item(), val_loss, val_acc))"
      ],
      "metadata": {
        "id": "nbDmuA1c1KmZ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V = len(words)\n",
        "model = CBOW(vocab_size=V, emb_size=50)\n",
        "train_epocs(model, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPWL_d_x1KpG",
        "outputId": "2ea15691-0386-4793-8955-a4c757d6920c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 0.525 val_loss: 0.527 --- val_accuracy: 0.536\n",
            "train_loss: 0.327 val_loss: 0.338 --- val_accuracy: 0.825\n",
            "train_loss: 0.233 val_loss: 0.270 --- val_accuracy: 0.891\n",
            "train_loss: 0.179 val_loss: 0.253 --- val_accuracy: 0.897\n",
            "train_loss: 0.109 val_loss: 0.265 --- val_accuracy: 0.897\n",
            "train_loss: 0.080 val_loss: 0.285 --- val_accuracy: 0.891\n",
            "train_loss: 0.052 val_loss: 0.315 --- val_accuracy: 0.884\n",
            "train_loss: 0.050 val_loss: 0.345 --- val_accuracy: 0.882\n",
            "train_loss: 0.049 val_loss: 0.380 --- val_accuracy: 0.883\n",
            "train_loss: 0.029 val_loss: 0.415 --- val_accuracy: 0.877\n",
            "train_loss: 0.023 val_loss: 0.446 --- val_accuracy: 0.879\n",
            "train_loss: 0.019 val_loss: 0.483 --- val_accuracy: 0.873\n",
            "train_loss: 0.014 val_loss: 0.508 --- val_accuracy: 0.876\n",
            "train_loss: 0.007 val_loss: 0.530 --- val_accuracy: 0.876\n",
            "train_loss: 0.016 val_loss: 0.554 --- val_accuracy: 0.876\n",
            "train_loss: 0.007 val_loss: 0.572 --- val_accuracy: 0.873\n",
            "train_loss: 0.006 val_loss: 0.583 --- val_accuracy: 0.873\n",
            "train_loss: 0.007 val_loss: 0.599 --- val_accuracy: 0.876\n",
            "train_loss: 0.008 val_loss: 0.610 --- val_accuracy: 0.877\n",
            "train_loss: 0.007 val_loss: 0.626 --- val_accuracy: 0.874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pju1404p1KsC"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}