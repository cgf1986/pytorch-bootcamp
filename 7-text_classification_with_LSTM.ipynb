{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import spacy\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from spacy.symbols import ORTH\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hartm7xDrtrz",
        "outputId": "ac6de863-6cbf-48e6-ef2a-1bdd1fd08ff7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add shortcut to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTrtaPtpsdS_",
        "outputId": "e22f5a96-f8f9-4914-810c-5b835808d159"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "Sentiment classification on the imdb dataset.\n",
        "https://ai.stanford.edu/~amaas/data/sentiment/"
      ],
      "metadata": {
        "id": "kO7Ze1Z-r30I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z1nvUxartvG",
        "outputId": "b79c01d0-3e9f-4e50-b4c9-04edbb825fed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir Data_Imdb\n",
        "# !wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "# !tar -zxvf aclImdb_v1.tar.gz -C Data_Imdb\n"
      ],
      "metadata": {
        "id": "LF-v7IAArtyM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "PATH = Path(\"Data_Imdb/aclImdb/\")\n",
        "list(PATH.iterdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0JNOs5Uy9X2",
        "outputId": "03251444-2ff8-4eda-8f76-60d7dfacda38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('Data_Imdb/aclImdb/imdb.vocab'),\n",
              " PosixPath('Data_Imdb/aclImdb/test'),\n",
              " PosixPath('Data_Imdb/aclImdb/imdbEr.txt'),\n",
              " PosixPath('Data_Imdb/aclImdb/README'),\n",
              " PosixPath('Data_Imdb/aclImdb/train')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = PATH/\"train/pos/0_9.txt\"\n",
        "path.read_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Hp2Z6LbBy9bZ",
        "outputId": "a84baf49-f9d8-4809-a197-7717975b71c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization\n"
      ],
      "metadata": {
        "id": "ImwITMRizQLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
        "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
        "\n",
        "my_tok = spacy.load('en_core_web_sm')\n",
        "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
      ],
      "metadata": {
        "id": "JTkGA5hNy9ep"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = PATH/\"train/pos/0_9.txt\"\n",
        "spacy_tok(path.read_text())[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7zz2q4Ay9hh",
        "outputId": "9f3d7186-7edb-4a6d-810c-0404553219e6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bromwell', 'High', 'is', 'a', 'cartoon', 'comedy', '.', 'It', 'ran', 'at']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vocab2index"
      ],
      "metadata": {
        "id": "8T6oyb1izsTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_files = list((PATH/\"train\"/\"pos\").iterdir())\n",
        "neg_files = list((PATH/\"train\"/\"neg\").iterdir())\n",
        "all_files = pos_files + neg_files\n",
        "all_files[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9Yxfzw5y9kZ",
        "outputId": "348acbcb-156a-4231-c79c-c22d53e38bbd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('Data_Imdb/aclImdb/train/pos/11546_9.txt'),\n",
              " PosixPath('Data_Imdb/aclImdb/train/pos/11422_8.txt'),\n",
              " PosixPath('Data_Imdb/aclImdb/train/pos/11534_7.txt'),\n",
              " PosixPath('Data_Imdb/aclImdb/train/pos/11815_10.txt'),\n",
              " PosixPath('Data_Imdb/aclImdb/train/pos/11632_7.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = Counter()\n",
        "for path in all_files:\n",
        "    counts.update(spacy_tok(path.read_text()))"
      ],
      "metadata": {
        "id": "OzfPtEn8y9nx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(counts.keys()))\n",
        "#counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF2ZGCHS0D_v",
        "outputId": "3605387c-8e8c-4e9c-a986-47c9ddc6b66e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in list(counts):\n",
        "    if counts[word] < 5:\n",
        "        del counts[word]\n",
        "\n",
        "len(counts.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx46NWfa0EGn",
        "outputId": "38cf7ef9-8285-4b86-f4f5-0ee1b216b0a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33893"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab2index = {\"\":0, \"UNK\":1}\n",
        "words = [\"\", \"UNK\"]\n",
        "for word in counts:\n",
        "    vocab2index[word] = len(words)\n",
        "    words.append(word)"
      ],
      "metadata": {
        "id": "orqABIN40wk8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vocab2index"
      ],
      "metadata": {
        "id": "i0CHVVZE0EJw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "qHIpLtPJ0bdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# note that spacy_tok takes a while run it just once\n",
        "def encode_sentence(path, vocab2index, N=400, padding_start=True):\n",
        "    x = spacy_tok(path.read_text())\n",
        "    enc = np.zeros(N, dtype=np.int32)\n",
        "    enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])\n",
        "    l = min(N, len(enc1))\n",
        "    if padding_start:\n",
        "        enc[N-l:] = enc1[:l]\n",
        "    else:\n",
        "        enc[:l] = enc1[:l]\n",
        "    return enc, l"
      ],
      "metadata": {
        "id": "gusx9Out-pWM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = PATH/\"train/neg/211_4.txt\"\n",
        "path.read_text()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "FPMsQWx7fLhg",
        "outputId": "afc562ce-2444-43f9-c6fe-e1271eca47fd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hilariously obvious \"drama\" about a bunch of high school (I think) kids who enjoy non-stop hip-hop, break dancing, graffiti and trying to become a dj at the Roxy--or something. To be totally honest I was so bored I forgot! Even people who love the music agree this movie is terribly acted and--as a drama--failed dismally. We\\'re supposed to find this kids likable and nice. I found them bland and boring. The one that I REALLY hated was Ramon. He does graffiti on subway trains and this is looked upon as great. Excuse me? He\\'s defacing public property that isn\\'t his to begin with. Also these \"great\" kids tap into the city\\'s electricity so they can hold a big dance party at an abandoned building. Uh huh. So we\\'re supposed to find a bunch of law breakers lovable and fun.<br /><br />I could forgive all that if the music was good but I can\\'t stand hip hop. The songs were--at best--mediocre and they were nonstop! They\\'re ALWAYS playing! It got to the point that I was fast-forwarding through the many endless music numbers. (Cut out the music and you haver a 30 minute movie--maybe) There are a few imaginative numbers--the subway dance fight, a truly funny Santa number and the climatic Roxy show. If you love hip hop here\\'s your movie. But it you\\'re looking for good drama mixed in--forget it. Also HOW did this get a PG rating? There\\'s an incredible amount of swearing in this.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_tok(path.read_text())[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdzMhHzu4mtI",
        "outputId": "87c7553f-1f2c-4f7e-9f19-f828d08612c0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hilariously',\n",
              " 'obvious',\n",
              " '\"',\n",
              " 'drama',\n",
              " '\"',\n",
              " 'about',\n",
              " 'a',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'high']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab2index['drama']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2Am_spt3hG6",
        "outputId": "670c6c4a-132c-4a00-b61f-940e9e3dcd4a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = PATH/\"train/neg/211_4.txt\"\n",
        "encode_sentence(path, vocab2index, N=400, padding_start=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM9aO18m0EQY",
        "outputId": "c3a81d76-b95e-4f66-c29f-daa287041d88"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            1,  2544,    89,   210,    89,   229,   105,  3569,    30,\n",
              "         1862,  2334,   171,   270,   732,   174,   540,   232,  1402,\n",
              "         3601,   398,  2034, 18018,   398,  7917,     8,  3969,  3025,\n",
              "            8, 20317,    14,  1323,    45,   178,   105,     1,   114,\n",
              "           68, 27668,   505,   172,   430,    21,  1439,   235,  1071,\n",
              "         4049,   270,    59,   253,  6283,   270,  1699,    81,  1126,\n",
              "          313,   232,  2286,    68,  1811,  3213,    19,   273,    70,\n",
              "         4974,    76,    14,   505,    42,   105,   210,   505,  7025,\n",
              "         8412,    21,   589,   348,  2984,    45,   784,    19,   540,\n",
              "         3400,    14,   380,    21,   270,  1375,   588, 11955,    14,\n",
              "         2527,    21,   109,   238,   155,   270,  7397,  4312,    59,\n",
              "         8933,    21,   613,   611, 20317,    72, 21634,  8160,    14,\n",
              "           19,    70,  5526,  2741,    42,    57,    21, 10553,   335,\n",
              "         1175,   613,    31,     1,  3023, 14655,   155,    70,   467,\n",
              "           64,    45,  2418,   147,    21,  1158,   133,    89,    57,\n",
              "           89,   540,  7130,    38,    68,  2229,    31,  6130,   253,\n",
              "           99,   307,  1477,   105,  1495,  3222,  2724,   114,   123,\n",
              "         6417,  4272,    21,  8793,  9135,    21,  1374,   401,   348,\n",
              "         2984,    45,   784,   105,  3569,    30,  6547, 27826,  2639,\n",
              "           14,  2021,    21,    10,   270,   714,  1760,    79,   155,\n",
              "          206,    68,  1811,    59,   268,   107,   270,   466,   467,\n",
              "         2190, 18018,  7917,    21,   109,  1868,   959,   505,   114,\n",
              "           74,   505,  2637,    14,    99,   959,  5820,    81,   608,\n",
              "          348, 18185,   840,    81,   227,  1077,    45,    68,   794,\n",
              "          155,   270,    59,  1146,   398, 30185,   465,    68,   127,\n",
              "         4614,  1811,  2620,    21,   171,  3269,   297,    68,  1811,\n",
              "           14,   207,     1,   105,   438,  2624,   273,   505,  1299,\n",
              "          174,   580,   100,   105,   198,  1762,  2620,   505,    68,\n",
              "        21634,  3222,  1697,     8,   105,   315,   527, 16890,  3563,\n",
              "           14,    68, 15638, 27668,   549,    21,   347,   207,  2286,\n",
              "        18018,  7917,   221,    31,   777,   273,    21,   259,    26,\n",
              "          207,   348,   208,    85,   268,   210,  6551,    18,   505,\n",
              "         1715,    26,    21,  1158,  6816,   571,    19,   645,   105,\n",
              "         3274,   301,  1175,   580,    31,   123,   717,  2131,    30,\n",
              "         5874,    18,    19,    21], dtype=int32), 310)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImdbDataset(Dataset):\n",
        "    def __init__(self, PATH, train=\"train\", N=400, padding_start=True):\n",
        "        self.path_to_images = PATH/train\n",
        "        self.pos_files = list((self.path_to_images/\"pos\").iterdir())\n",
        "        self.neg_files = list((self.path_to_images/\"neg\").iterdir())\n",
        "        self.files = self.pos_files + self.neg_files\n",
        "        # pos 1, neg 0\n",
        "        self.y = np.concatenate((np.ones(len(self.pos_files), dtype=int),\n",
        "                                np.zeros(len(self.neg_files), dtype=int)), axis=0)\n",
        "        # it is important to run encode_sentence in the init\n",
        "        self.X = [encode_sentence(path, vocab2index, N, padding_start) for path in self.files]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        x, s = self.X[idx]\n",
        "        return x, s, self.y[idx]"
      ],
      "metadata": {
        "id": "xYRupRWe0iED"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_v0 = ImdbDataset(PATH, padding_start=True)\n",
        "valid_ds_v0 = ImdbDataset(PATH, \"test\", padding_start=True)"
      ],
      "metadata": {
        "id": "Hiq1BVUS0iGo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1000\n",
        "train_dl_v0 = DataLoader(train_ds_v0, batch_size=batch_size, shuffle=True)\n",
        "valid_dl_v0 = DataLoader(valid_ds_v0, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "J6chJK4B0iJY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_v0[1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0YtWfYW0iMQ",
        "outputId": "20a19ac0-acd8-454a-f97c-2c733e2ab3e1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   2,  27,  19, 100, 101,\n",
              "         85,  56, 102, 103,   5, 104,  24, 105, 106,  15, 107, 108,  61,\n",
              "        109, 110, 111,  16,  13,  11, 112,  67,  27, 113,  19, 114, 115,\n",
              "        116,  49,  21, 117, 118, 119, 120,   1,  19, 121, 122, 123,  24,\n",
              "        124, 125, 126, 127,  14, 128,  15, 129,  19, 130,  58, 131,  50,\n",
              "        132,  11,  97,  67,  27,  44, 133, 134,  30,  24, 135,  27, 136,\n",
              "        137, 138, 139,  46, 140,  19, 141, 142,  21, 143,  46, 144, 145,\n",
              "         24, 135, 126,  79, 146,  41, 147, 148, 149, 150,  19, 151,  21,\n",
              "         19, 152,  24, 135, 126, 153,  59,  60,  35, 154, 155, 156, 157,\n",
              "         19, 158,  41, 159, 160,  11,  97,  72, 126, 161, 126, 162,  61,\n",
              "         41, 163, 164, 133, 165, 166, 167, 168, 169,  24], dtype=int32),\n",
              " 132,\n",
              " 1)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "BnHKMApV1BxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input dim is the dimension of the embedding for each word (2 in the example)\n",
        "# Output dim is the dimension of the hidden layer (4 in this example)\n",
        "# batch_first – If True, then the input and output tensors are provided as (batch, seq, feature). \n",
        "lstm = nn.LSTM(2, 4, batch_first=True)  "
      ],
      "metadata": {
        "id": "vU5q6b8m0iPY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [torch.randn(1, 2) for _ in range(5)] # make a sequence of length 5\n",
        "inputs = torch.cat(inputs).view(1, len(inputs), -1)\n",
        "print(inputs.shape)\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzpXQV3i1G97",
        "outputId": "dd444f01-d739-42e5-81ac-671d97c3791e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.2389, -0.2758],\n",
              "         [ 0.1086, -0.6741],\n",
              "         [-0.2651,  0.1672],\n",
              "         [-1.1916, -1.0372],\n",
              "         [ 0.2675, -1.7877]]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNNs with batch_first=True assume this input shape\n",
        "# input shape should be bash_size x seq_len x embedding dimension\n",
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqdvapuC1HBT",
        "outputId": "1c886000-5798-4cc9-886d-46d16fc9c155"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out, (hidden, cell) = lstm(inputs)\n"
      ],
      "metadata": {
        "id": "IYu7MG3c1HD5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(out.shape)\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G9424WM1HHB",
        "outputId": "81213883-dab1-4bc3-fba0-511026b01f9c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0316, -0.0424,  0.0687, -0.0839],\n",
              "         [ 0.0583, -0.0238,  0.0999, -0.0924],\n",
              "         [ 0.0496, -0.0644,  0.1124, -0.1580],\n",
              "         [ 0.0994, -0.0650,  0.1343, -0.2784],\n",
              "         [ 0.1083,  0.0412,  0.1601, -0.1735]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTFdx3zZ1HKZ",
        "outputId": "db1fb5fe-734a-4ec5-b714-8a8835595c5c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1083,  0.0412,  0.1601, -0.1735]]], grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "WAacPSWb1Pe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMV0Model(torch.nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
        "        super(LSTMV0Model,self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        out_pack, (ht, ct) = self.lstm(x)\n",
        "        return self.linear(ht[-1])"
      ],
      "metadata": {
        "id": "z1Cg0k951TVj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epocs_v0(model, epochs=10, lr=0.001):\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        sum_loss = 0.0\n",
        "        total = 0\n",
        "        for x, s, y in train_dl:\n",
        "            # s is not used in this model\n",
        "            x = x.long().cuda()\n",
        "            y = y.float().cuda()\n",
        "            y_pred = model(x)\n",
        "            optimizer.zero_grad()\n",
        "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            sum_loss += loss.item()*y.shape[0]\n",
        "            total += y.shape[0]\n",
        "        val_loss, val_acc = val_metrics_v0(model, val_dl)\n",
        "        if i % 5 == 1:\n",
        "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
      ],
      "metadata": {
        "id": "olAHAkbc1TYJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_metrics_v0(model, valid_dl):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sum_loss = 0.0\n",
        "    for x, s, y in valid_dl:\n",
        "        # s is not used here\n",
        "        x = x.long().cuda()\n",
        "        y = y.float().unsqueeze(1).cuda()\n",
        "        y_hat = model(x)\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        y_pred = y_hat > 0\n",
        "        correct += (y_pred.float() == y).float().sum()\n",
        "        total += y.shape[0]\n",
        "        sum_loss += loss.item()*y.shape[0]\n",
        "    return sum_loss/total, correct/total"
      ],
      "metadata": {
        "id": "7meX5SwW1Ta9"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5000\n",
        "train_dl = DataLoader(train_ds_v0, batch_size=batch_size, shuffle=True)\n",
        "val_dl = DataLoader(valid_ds_v0, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "S-MRr_xt1Tdh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(words)\n",
        "print(vocab_size)\n",
        "model_v0 = LSTMV0Model(vocab_size, 50, 50).cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "QO5n5vK-1TgJ",
        "outputId": "f92e400b-532f-4494-b142-7d5b128163e3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33895\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-c653558e5bbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_v0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMV0Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_epocs_v0(model_v0, epochs=30, lr=0.01)\n"
      ],
      "metadata": {
        "id": "Mct26KUZ1TjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qJf71PXTrr6B"
      }
    }
  ]
}