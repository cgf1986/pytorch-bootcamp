{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import spacy\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from spacy.symbols import ORTH\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence \n"
      ],
      "metadata": {
        "id": "hartm7xDrtrz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add shortcut to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTrtaPtpsdS_",
        "outputId": "f4fe990e-a25a-409a-f4a1-03ba4fece8e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "Sentiment classification on the imdb dataset.\n",
        "https://ai.stanford.edu/~amaas/data/sentiment/"
      ],
      "metadata": {
        "id": "kO7Ze1Z-r30I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z1nvUxartvG",
        "outputId": "4f51ba7c-fda0-401e-9224-454cd0f82a6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir Data_Imdb\n",
        "# !wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "# !tar -zxvf aclImdb_v1.tar.gz -C Data_Imdb\n"
      ],
      "metadata": {
        "id": "LF-v7IAArtyM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "PATH = Path(\"Data_Imdb/aclImdb/\")\n",
        "list(PATH.iterdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0JNOs5Uy9X2",
        "outputId": "d42d17bf-b27f-4508-808b-2f2240f16003"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('Data_Imdb/aclImdb/test'),\n",
              " PosixPath('Data_Imdb/aclImdb/train'),\n",
              " PosixPath('Data_Imdb/aclImdb/imdbEr.txt'),\n",
              " PosixPath('Data_Imdb/aclImdb/imdb.vocab'),\n",
              " PosixPath('Data_Imdb/aclImdb/README')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = PATH/\"train/pos/0_9.txt\"\n",
        "path.read_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Hp2Z6LbBy9bZ",
        "outputId": "0f7d5f6a-7ca5-48bf-ff11-0157a176c848"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization\n"
      ],
      "metadata": {
        "id": "ImwITMRizQLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
        "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
        "\n",
        "my_tok = spacy.load('en_core_web_sm')\n",
        "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
      ],
      "metadata": {
        "id": "JTkGA5hNy9ep"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = PATH/\"train/pos/0_9.txt\"\n",
        "spacy_tok(path.read_text())[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7zz2q4Ay9hh",
        "outputId": "ca1c4549-9ed8-4098-89fe-db6c47eae405"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bromwell', 'High', 'is', 'a', 'cartoon', 'comedy', '.', 'It', 'ran', 'at']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vocab2index"
      ],
      "metadata": {
        "id": "8T6oyb1izsTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_files = list((PATH/\"train\"/\"pos\").iterdir())\n",
        "neg_files = list((PATH/\"train\"/\"neg\").iterdir())\n",
        "all_files = pos_files + neg_files\n",
        "all_files[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9Yxfzw5y9kZ",
        "outputId": "7f9e4fab-a7be-4e9e-8a67-7d7416308d7e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('Data_Imdb/aclImdb/train/pos/127_7.txt'),\n",
              " PosixPath('Data_Imdb/aclImdb/train/pos/126_10.txt'),\n",
              " PosixPath('Data_Imdb/aclImdb/train/pos/125_7.txt'),\n",
              " PosixPath('Data_Imdb/aclImdb/train/pos/124_10.txt'),\n",
              " PosixPath('Data_Imdb/aclImdb/train/pos/123_10.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = Counter()\n",
        "for path in all_files:\n",
        "    counts.update(spacy_tok(path.read_text()))"
      ],
      "metadata": {
        "id": "OzfPtEn8y9nx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(counts.keys()))\n",
        "#counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF2ZGCHS0D_v",
        "outputId": "2fc6d9b9-082e-46c2-f3ca-d7c7c3438906"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in list(counts):\n",
        "    if counts[word] < 5:\n",
        "        del counts[word]\n",
        "\n",
        "len(counts.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx46NWfa0EGn",
        "outputId": "221c26a2-b0d9-481b-dc4c-53793af4b224"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33893"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab2index = {\"\":0, \"UNK\":1}\n",
        "words = [\"\", \"UNK\"]\n",
        "for word in counts:\n",
        "    vocab2index[word] = len(words)\n",
        "    words.append(word)"
      ],
      "metadata": {
        "id": "orqABIN40wk8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vocab2index"
      ],
      "metadata": {
        "id": "i0CHVVZE0EJw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "qHIpLtPJ0bdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# note that spacy_tok takes a while run it just once\n",
        "def encode_sentence(path, vocab2index, N=400, padding_start=True):\n",
        "    x = spacy_tok(path.read_text())\n",
        "    enc = np.zeros(N, dtype=np.int32)\n",
        "    enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])\n",
        "    l = min(N, len(enc1))\n",
        "    if padding_start:\n",
        "        enc[N-l:] = enc1[:l]\n",
        "    else:\n",
        "        enc[:l] = enc1[:l]\n",
        "    return enc, l"
      ],
      "metadata": {
        "id": "gusx9Out-pWM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = PATH/\"train/neg/211_4.txt\"\n",
        "path.read_text()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "FPMsQWx7fLhg",
        "outputId": "c8693a89-1c81-41f2-8823-6b6e743cfa88"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hilariously obvious \"drama\" about a bunch of high school (I think) kids who enjoy non-stop hip-hop, break dancing, graffiti and trying to become a dj at the Roxy--or something. To be totally honest I was so bored I forgot! Even people who love the music agree this movie is terribly acted and--as a drama--failed dismally. We\\'re supposed to find this kids likable and nice. I found them bland and boring. The one that I REALLY hated was Ramon. He does graffiti on subway trains and this is looked upon as great. Excuse me? He\\'s defacing public property that isn\\'t his to begin with. Also these \"great\" kids tap into the city\\'s electricity so they can hold a big dance party at an abandoned building. Uh huh. So we\\'re supposed to find a bunch of law breakers lovable and fun.<br /><br />I could forgive all that if the music was good but I can\\'t stand hip hop. The songs were--at best--mediocre and they were nonstop! They\\'re ALWAYS playing! It got to the point that I was fast-forwarding through the many endless music numbers. (Cut out the music and you haver a 30 minute movie--maybe) There are a few imaginative numbers--the subway dance fight, a truly funny Santa number and the climatic Roxy show. If you love hip hop here\\'s your movie. But it you\\'re looking for good drama mixed in--forget it. Also HOW did this get a PG rating? There\\'s an incredible amount of swearing in this.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_tok(path.read_text())[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdzMhHzu4mtI",
        "outputId": "b1a75411-2a12-47bf-aca7-6ab52e049ff4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hilariously',\n",
              " 'obvious',\n",
              " '\"',\n",
              " 'drama',\n",
              " '\"',\n",
              " 'about',\n",
              " 'a',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'high']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab2index['drama']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2Am_spt3hG6",
        "outputId": "731f1abf-c0a8-4c4d-bbd2-dee1c7172a00"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "776"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = PATH/\"train/neg/211_4.txt\"\n",
        "encode_sentence(path, vocab2index, N=400, padding_start=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM9aO18m0EQY",
        "outputId": "2a751a3a-015c-46ae-b4e2-e1e7fdea792f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            1,  2647,    87,   776,    87,   417,    39,  2200,    21,\n",
              "          290,  1625,   288,    56,   743,   292,  2008,    35,  1623,\n",
              "         5452,    14,   310, 11887,    14, 11888,    11,  4404,  3980,\n",
              "           11, 11911,    46,   172,    59,  3339,    39,     1,   289,\n",
              "           19,  8361,  1835,   597,   744,    24,  1456,   485,  1482,\n",
              "         2038,    56,   424,   189,  3271,    56,  3419,   354,  1460,\n",
              "          366,    35,   416,    19,   944,   796,    67,    85,    27,\n",
              "         4037,  2215,    46,  1835,    74,    39,   776,  1835, 10047,\n",
              "        26352,    24,   723,  1422,  1956,    59,   749,    67,  2008,\n",
              "         4007,    46,  1474,    24,    56,   509,   177,  4369,    46,\n",
              "         2045,    24,     8,    89,    61,    56, 12307,  3782,   424,\n",
              "        11912,    24,   182,    42, 11911,   214, 11914,  1021,    46,\n",
              "           67,    27,  3272,  2697,    74,   435,    24,  7670,   340,\n",
              "          879,   182,   126,     1,  1641,  2613,    61,    27,    43,\n",
              "          133,    59,  2376,     7,    24,  1221,   122,    87,   435,\n",
              "           87,  2008,  5124,   164,    19,  3558,   126, 19898,   189,\n",
              "          233,   411,  2204,    39,  1542,  3981,  1491,   289,    32,\n",
              "          668, 10571,    24, 12549, 12550,    24,  1652,   598,  1422,\n",
              "         1956,    59,   749,    39,  2200,    21,  2023, 11897,  6329,\n",
              "           46,  1834,    24,    54,    56,   318, 10414,    49,    61,\n",
              "          488,    19,   944,   424,   632,    97,    56,   664,    43,\n",
              "         2460, 11887, 11888,    24,     8,  1822,   150,  1835,   289,\n",
              "          134,  1835,  3991,    46,   233,   150, 23186,   354,  2297,\n",
              "         1422, 10272,  1048,   354,   135,   437,    59,    19,   486,\n",
              "           61,    56,   424,  3617,    14, 27327,   246,    19,   190,\n",
              "         6468,   944,  6448,    24,   288, 18394,   173,    19,   944,\n",
              "           46,   106,     1,    39,  4927,  3197,    85,  1835,  1095,\n",
              "          292,    31,   109,    39,  1827,   694,  6448,  1835,    19,\n",
              "        11914,  3981,  3022,    11,    39,   461,  1959, 10822,  1866,\n",
              "           46,    19, 14311,  8361,   621,    24,   105,   106,   416,\n",
              "        11887, 11888,   160,   126,   352,    85,    24,    55,    72,\n",
              "          106,  1422,  1664,   116,   632,   776,   991,     5,  1835,\n",
              "          540,    72,    24,  1221, 23147,   925,    67,   888,    39,\n",
              "         8481,  1397,   879,    31,   126,    32,  2741,  1934,    21,\n",
              "        12025,     5,    67,    24], dtype=int32), 310)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImdbDataset(Dataset):\n",
        "    def __init__(self, PATH, train=\"train\", N=400, padding_start=True):\n",
        "        self.path_to_images = PATH/train\n",
        "        self.pos_files = list((self.path_to_images/\"pos\").iterdir())\n",
        "        self.neg_files = list((self.path_to_images/\"neg\").iterdir())\n",
        "        self.files = self.pos_files + self.neg_files\n",
        "        # pos 1, neg 0\n",
        "        self.y = np.concatenate((np.ones(len(self.pos_files), dtype=int),\n",
        "                                np.zeros(len(self.neg_files), dtype=int)), axis=0)\n",
        "        # it is important to run encode_sentence in the init\n",
        "        self.X = [encode_sentence(path, vocab2index, N, padding_start) for path in self.files]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        x, s = self.X[idx]\n",
        "        return x, s, self.y[idx]"
      ],
      "metadata": {
        "id": "xYRupRWe0iED"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_v0 = ImdbDataset(PATH, padding_start=True)\n",
        "valid_ds_v0 = ImdbDataset(PATH, \"test\", padding_start=True)"
      ],
      "metadata": {
        "id": "Hiq1BVUS0iGo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1000\n",
        "train_dl_v0 = DataLoader(train_ds_v0, batch_size=batch_size, shuffle=True)\n",
        "valid_dl_v0 = DataLoader(valid_ds_v0, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "J6chJK4B0iJY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_v0[1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0YtWfYW0iMQ",
        "outputId": "79502d23-aae3-41af-eb6e-646211ced06d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   2,  27,  19, 100, 101,\n",
              "         85,  56, 102, 103,   5, 104,  24, 105, 106,  15, 107, 108,  61,\n",
              "        109, 110, 111,  16,  13,  11, 112,  67,  27, 113,  19, 114, 115,\n",
              "        116,  49,  21, 117, 118, 119, 120,   1,  19, 121, 122, 123,  24,\n",
              "        124, 125, 126, 127,  14, 128,  15, 129,  19, 130,  58, 131,  50,\n",
              "        132,  11,  97,  67,  27,  44, 133, 134,  30,  24, 135,  27, 136,\n",
              "        137, 138, 139,  46, 140,  19, 141, 142,  21, 143,  46, 144, 145,\n",
              "         24, 135, 126,  79, 146,  41, 147, 148, 149, 150,  19, 151,  21,\n",
              "         19, 152,  24, 135, 126, 153,  59,  60,  35, 154, 155, 156, 157,\n",
              "         19, 158,  41, 159, 160,  11,  97,  72, 126, 161, 126, 162,  61,\n",
              "         41, 163, 164, 133, 165, 166, 167, 168, 169,  24], dtype=int32),\n",
              " 132,\n",
              " 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "BnHKMApV1BxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input dim is the dimension of the embedding for each word (2 in the example)\n",
        "# Output dim is the dimension of the hidden layer (4 in this example)\n",
        "# batch_first – If True, then the input and output tensors are provided as (batch, seq, feature). \n",
        "lstm = nn.LSTM(2, 4, batch_first=True)  "
      ],
      "metadata": {
        "id": "vU5q6b8m0iPY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [torch.randn(1, 2) for _ in range(5)] # make a sequence of length 5\n",
        "inputs = torch.cat(inputs).view(1, len(inputs), -1)\n",
        "print(inputs.shape)\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzpXQV3i1G97",
        "outputId": "e1389acb-c287-4b96-f228-762d6a6217b9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.2786, -1.0062],\n",
              "         [ 0.5628,  0.6482],\n",
              "         [-2.1092,  0.3702],\n",
              "         [ 1.6360, -1.9122],\n",
              "         [ 0.8610, -1.0903]]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNNs with batch_first=True assume this input shape\n",
        "# input shape should be bash_size x seq_len x embedding dimension\n",
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqdvapuC1HBT",
        "outputId": "9804d238-ebdc-46e7-81ac-e5f2afe87510"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out, (hidden, cell) = lstm(inputs)\n"
      ],
      "metadata": {
        "id": "IYu7MG3c1HD5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(out.shape)\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G9424WM1HHB",
        "outputId": "a8b361be-67ca-4572-ac72-1ed3c5d1358a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1088,  0.2179, -0.0648, -0.2143],\n",
              "         [ 0.0019,  0.2203,  0.0316, -0.1316],\n",
              "         [ 0.0357,  0.2381,  0.0104, -0.1598],\n",
              "         [ 0.0298,  0.4121, -0.0069, -0.2412],\n",
              "         [ 0.0555,  0.3779,  0.0136, -0.3631]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTFdx3zZ1HKZ",
        "outputId": "a8d0d19b-975b-4f5f-dc3c-f699c3ecfff8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0555,  0.3779,  0.0136, -0.3631]]], grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "WAacPSWb1Pe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMV0Model(torch.nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
        "        super(LSTMV0Model,self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        out_pack, (ht, ct) = self.lstm(x)\n",
        "        return self.linear(ht[-1])"
      ],
      "metadata": {
        "id": "z1Cg0k951TVj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epocs_v0(model, epochs=10, lr=0.001):\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        sum_loss = 0.0\n",
        "        total = 0\n",
        "        for x, s, y in train_dl:\n",
        "            # s is not used in this model\n",
        "            x = x.long().cuda()\n",
        "            y = y.float().cuda()\n",
        "            y_pred = model(x)\n",
        "            optimizer.zero_grad()\n",
        "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            sum_loss += loss.item()*y.shape[0]\n",
        "            total += y.shape[0]\n",
        "        val_loss, val_acc = val_metrics_v0(model, val_dl)\n",
        "        if i % 5 == 1:\n",
        "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
      ],
      "metadata": {
        "id": "olAHAkbc1TYJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_metrics_v0(model, valid_dl):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sum_loss = 0.0\n",
        "    for x, s, y in valid_dl:\n",
        "        # s is not used here\n",
        "        x = x.long().cuda()\n",
        "        y = y.float().unsqueeze(1).cuda()\n",
        "        y_hat = model(x)\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        y_pred = y_hat > 0\n",
        "        correct += (y_pred.float() == y).float().sum()\n",
        "        total += y.shape[0]\n",
        "        sum_loss += loss.item()*y.shape[0]\n",
        "    return sum_loss/total, correct/total"
      ],
      "metadata": {
        "id": "7meX5SwW1Ta9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 500\n",
        "train_dl = DataLoader(train_ds_v0, batch_size=batch_size, shuffle=True)\n",
        "val_dl = DataLoader(valid_ds_v0, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "S-MRr_xt1Tdh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(words)\n",
        "print(vocab_size)\n",
        "model_v0 = LSTMV0Model(vocab_size, 50, 30).cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO5n5vK-1TgJ",
        "outputId": "b9ecfebc-5ebe-4f7d-e53b-cd96d52449f2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_epocs_v0(model_v0, epochs=30, lr=0.01)\n"
      ],
      "metadata": {
        "id": "Mct26KUZ1TjE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19496618-0377-4b1e-eafc-85f56fd94e9c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.648 val loss 0.703 and val accuracy 0.507\n",
            "train loss 0.237 val loss 0.315 and val accuracy 0.870\n",
            "train loss 0.122 val loss 0.355 and val accuracy 0.873\n",
            "train loss 0.065 val loss 0.542 and val accuracy 0.857\n",
            "train loss 0.044 val loss 0.536 and val accuracy 0.858\n",
            "train loss 0.029 val loss 0.713 and val accuracy 0.850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qJf71PXTrr6B"
      }
    }
  ]
}